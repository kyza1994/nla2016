{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 7: Matrix decompositions and how we compute them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap of the previous lecture\n",
    "- Eigenvectors and eigenvalues\n",
    "- Characteristic polynomial and why it is a bad idea\n",
    "- Power method: $x := Ax$\n",
    "- Gershgorin theorem\n",
    "- Schur theorem: $A = U T U^*$ \n",
    "- Normal matrices: $A^* A = A A^*$\n",
    "- Two advanced topic: pseudospectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today lecture\n",
    "Today we will talk about **matrix factorizations**\n",
    "\n",
    "- LU decomposition and Gaussian elimination -- already covered\n",
    "- QR decomposition and Gram-Schmidt algorithm \n",
    "- Schur decomposition and QR-algorithm\n",
    "- Few words about the SVD decomposition\n",
    "\n",
    "We already introduced QR decomposition some time ago, but now we are going to do it in more details.  \n",
    "\n",
    "These are the basic **matrix factorizations** in numerical linear algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## General concept of matrix factorization\n",
    "\n",
    "In numerical linear algebra we need to solve different tasks, for example:\n",
    "\n",
    "- Solve linear systems $Ax = f$\n",
    "- Compute eigenvalues / eigenvectors\n",
    "- Compute singular values / singular vectors\n",
    "- Compute inverses, even sometimes determinants \n",
    "- Compute **matrix functions** like $\\exp(A), \\cos(A)$ (these are not elementwise functions)\n",
    "\n",
    "In order to do this, we represent the matrix as a sum and/or product of matrices with **simpler structure**,  \n",
    "such that we can solve abovementioned tasks faster / in a more stable form.\n",
    "\n",
    "What is a **simpler structure**?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a simpler structure\n",
    "We already encountered several classes of matrices **with structure**. \n",
    "\n",
    "In dense matrix business, the most important classes are\n",
    "\n",
    "**unitary matrices** ($U^* U = I$, why?), **upper/lower triangular matrices **, **diagonal matrices**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other classes of structured matrices\n",
    "\n",
    "For **sparse matrices** the sparse constraints are often included in the factorizations.  \n",
    "\n",
    "For **Toeplitz matrices** an important class of matrices is the class of matrices with **low displacement rank**, \n",
    "\n",
    "which is based on the low-rank matrices. \n",
    "\n",
    "The class of **low-rank matrices** and **block low-rank matrices** is everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plan\n",
    "The plan for today's lecture is to discuss the decompositions one-by-one and point out:\n",
    "- How to compute a particular decomposition\n",
    "- When the decomposition exists \n",
    "- What is done in **real life** (LAPACK)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decompositions we want to discuss today\n",
    "- LU factorization & Cholesky factorization -- quick reminder, already done.\n",
    "- QR-decomposition and Gram-Schmidt algorithm\n",
    "- 1 slide about the SVD (more tomorrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PLU decomposition\n",
    "\n",
    "Any nonsingular matrix can be factored as \n",
    "\n",
    "$$A = P L U, $$\n",
    "where $P$ is a permutation matrix, $L$ is a **lower triangular matrix**, $U$ is an **upper triangular**\n",
    "\n",
    "**Main goal** of the LU decomposition is to solve linear systems, because\n",
    "\n",
    "$$\n",
    "    A^{-1} f = (L U)^{-1} f = U^{-1} L^{-1} f, \n",
    "$$\n",
    "\n",
    "and this reduces to the solution of two linear systems \n",
    "$$\n",
    "     L y = f,  \\quad U x = y.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Positive definite matrices and Cholesky decomposition, reminder\n",
    "\n",
    "If the matrix is Hermitian Positive Definite,\n",
    "\n",
    "i.e. \n",
    "\n",
    "$$A = A^*, \\quad (Ax, x) > 0, \\quad x \\ne 0,$$\n",
    "\n",
    "then it can be factored as \n",
    "\n",
    "$$A = RR^*,$$\n",
    "\n",
    "where $R$ is upper triangular.\n",
    "\n",
    "We will need this for the QR decomposition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## QR-decomposition\n",
    "The next decomposition: **QR** decomposition. Again from the name it is clear that a matrix is represented as a product  \n",
    "$$\n",
    "    A = Q R, \n",
    "$$\n",
    "where $Q$ is an **orthogonal (unitary)** matrix and $R$ is **upper triangular**.  \n",
    "\n",
    "The matrix sizes: $Q$ is $n \\times m$, $R$ is $m \\times m$ if $n\\geq m$.\n",
    "\n",
    "QR-factorization is defined for **any rectangular matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## QR-decomposition: applications\n",
    "\n",
    "This algorithm plays a crucial role in many problems:\n",
    "- Computing orthogonal bases in a linear space\n",
    "- Used in the preprocessing step for the SVD\n",
    "- QR-algorithm for the computation of eigenvectors and eigenvalues (one of the 10 most important algorithms of the 20th century) is    based on the QR-decomposition\n",
    "- Solving overdetermined systems of linear equations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## QR-factorization and least squares\n",
    "\n",
    "Suppose we need to solve\n",
    "\n",
    "$$\\Vert A x - f \\Vert_2 \\rightarrow \\min_x,$$\n",
    "\n",
    "where $A$ is $n \\times m$, $n \\geq m$.\n",
    "\n",
    "Then we factorize\n",
    "\n",
    "$$A = Q R,$$\n",
    "\n",
    "and\n",
    "\n",
    "$z = R x$, we have\n",
    "\n",
    "$$\\Vert Q z - f \\Vert_2 \\rightarrow \\min, $$\n",
    "\n",
    "thus \n",
    "\n",
    "$$z = (Q^* Q)^{-1} Q^* f = Q^* f,$$\n",
    "\n",
    "and $x$ can be recovered from \n",
    "\n",
    "$$R x = z.$$\n",
    "\n",
    "Note that this is a square system of linear equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Short side note: randomized least squares\n",
    "\n",
    "One of the efficient ways to solve really overdetermined ($n\\gg m$) system of linear equations is to use Kaczmarz method.\n",
    "\n",
    "Instead of solving all equations, pick one randomly, which reads\n",
    "\n",
    "$$a^{\\top}_i x = f_i,$$\n",
    "\n",
    "and given an approximation $x_k$ try to find $x_{k+1}$ as \n",
    "\n",
    "$$x_{k+1} = \\arg \\min_x \\Vert x - x_k \\Vert, \\quad \\mbox{s. t.} \\quad  a^{\\top}_i x = f_i.$$\n",
    "\n",
    "a simple analysis gives \n",
    "\n",
    "$$x_{k+1} = x_k - \\frac{(a_i, x_k) - b_i}{(a_i, a_i)} a_i. $$\n",
    "A cheap update, but the analysis is quite complicated.\n",
    "If time permits, we will cover randomized algorithms of linear algebra in a separate lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Theorem:**\n",
    "Every rectangular $n \\times m$ matrix, $n \\geq m$ matrix has a QR-decomposition. \n",
    "\n",
    "\n",
    "There are several ways to prove it and compute it:\n",
    "\n",
    "- Theoretical: using the Gram matrices and Cholesky factorization\n",
    "- Geometrical: using the Gram-Schmidt orthogonalization\n",
    "- Practical: using Householder/Givens transformations \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Proof using Cholesky decomposition\n",
    "If we have the representation of the form\n",
    "$$A = QR,$$\n",
    "then $A^* A = ( Q R)^* (QR)  = R^* (Q^* Q) R = R^* R$, the matrix $A^* A$ is called **Gram matrix**, and its elements are scalar products of the columns of $A$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Proof using Cholesky decomposition (full column rank)\n",
    "\n",
    "Assume that $A$ has **full column rank**. Then, it is simple to show that $A^* A$ is positive definite:\n",
    "\n",
    "$$\n",
    "   (A^* A y, y) = (Ay, Ay)^2 = \\Vert Ay \\Vert  > 0, \\quad y\\not = 0.\n",
    "$$\n",
    "\n",
    "Therefore, $A^* A = R^* R$ always exists.\n",
    "\n",
    "Then the matrix $A R^{-1}$ is unitary:  \n",
    "\n",
    "$$\n",
    "   (A R^{-1})^* (AR^{-1})= R^{-*} A^* A R^{-1} = R^{-*} R^* R R^{-1} = I.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Proof using Cholesky decomposition (rank-deficient case)\n",
    "When an $n \\times m$ matrix does not have full column rank, it is said to be **rank-deficient**.  \n",
    "\n",
    "The QR-decomposition, however, also exists.\n",
    "\n",
    "For any **rank-deficient matrix** there is a sequence of full-column rank matrices $A_k$ such that $A_k \\rightarrow A$ (why?).\n",
    "\n",
    "Each $A_k$ can be decomposed as $A_k = Q_k R_k$. \n",
    "\n",
    "The set of all unitary matrices is compact, thus there exists a converging subsequence $Q_{n_k} \\rightarrow Q$ (why?),\n",
    "\n",
    "and $Q^* A_k \\rightarrow Q^* A = R$, which is triangular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stability of QR-decomposition via Cholesky decomposition\n",
    "So, the simplest way to compute QR-decomposition is then\n",
    "\n",
    "$$A^* A = R^* R,$$\n",
    "\n",
    "(Cholesky factorization)\n",
    "\n",
    "$$Q = A R^{-1}.$$\n",
    "\n",
    "It is a **bad idea** for numerical stability. Let us do some demo (for a submatrix of the Hilbert matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built-in QR orth 1.11469516053e-15\n",
      "Via Cholesky: 0.105536980788\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 20\n",
    "r = 8\n",
    "#a = np.random.randn(n, r)\n",
    "a = [[1.0/(i+j+0.5) for i in range(r)] for j in range(n)]\n",
    "a = np.array(a)\n",
    "q, Rmat = np.linalg.qr(a)\n",
    "e = np.eye(r)\n",
    "print 'Built-in QR orth', np.linalg.norm(np.dot(q.T, q) - e)\n",
    "gram_matrix = a.T.dot(a)\n",
    "Rmat1 = np.linalg.cholesky(gram_matrix)\n",
    "q1 = np.dot(a, np.linalg.inv(Rmat1.T))\n",
    "print 'Via Cholesky:', np.linalg.norm(np.dot(q1.T, q1) - e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Second way: Gram-Schmidt orthogonalization\n",
    "QR-decomposition is a mathematical way of writing down the Gram-Schmidt orthogonalization process.  \n",
    "Given a sequence of vectors $a_1, \\ldots, a_m$ we want to find orthogonal basis $q_1, \\ldots, q_m$ such that every $a_i$ is a linear combination of such vectors.  \n",
    "\n",
    "**Gram-Schmidt:**\n",
    "1. $q_1 := a_1/\\Vert a_1 \\Vert$\n",
    "2. $q_2 := a_2 - (a_2, q_1) q_1, \\quad q_2 := q_2/\\Vert q_2 \\Vert$\n",
    "3. $q_3 := a_3 - (a_3, q_1) q_1 - (a_3, q_2) q_2, \\quad q_2 := q_3/\\Vert q_3 \\Vert$\n",
    "4. And go on  \n",
    "\n",
    "Note that the transformation from $Q$ to $A$ has triangular structure, since from the $k$-th vector we subtract only the previous ones. It follows from the fact that the product of triangular matrices is a triangular matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modified Gram-Schmidt\n",
    "Gram-Schmidt can be very unstable (i.e., the produced vectors will be not orthogonal, especially if $q_k$ has small norm).  \n",
    "This is called **loss of orthogonality**.  \n",
    "\n",
    "There is a remedy, called **modified Gram-Schmidt** method. \n",
    "Instead of doing \n",
    "\n",
    "$$q_k := a_k - (a_k, q_1) q_1 - \\ldots - (a_k, q_{k-1}) q_{k-1}$$\n",
    "\n",
    "we do it step-by-step. First we set $q_k := a_k$ and orthogonalize sequentially:\n",
    "\n",
    "$$\n",
    "   q_k := q_k - (q_k, q_1)q_1, \\quad q_k := q_{k} - (q_k,q_2)q_2, \\ldots\n",
    "$$\n",
    "\n",
    "In exact arithmetic, it is the same. In floating point it is absolutely different!\n",
    "\n",
    "Note that the complexity is $\\mathcal{O}(nm^2)$ operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## QR-decomposition: the (almost) practical way\n",
    "\n",
    "If $A = QR$, then  \n",
    "$$\n",
    "R = Q^* A,\n",
    "$$\n",
    "and we need to find a certain orthogonal matrix $Q$ that brings a matrix into orthogonal form.  \n",
    "For simplicity, we will look for an $n \\times n$ matrix such that\n",
    "$$\n",
    "   Q^* A = \\begin{bmatrix}\n",
    "   * & * & *  \\\\\n",
    "   0 & * & * \\\\\n",
    "   0 & 0 & * \\\\\n",
    "   &0_{(n-m) \\times m}\n",
    "   \\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will do it column-by-column.  \n",
    "First, we find a Householder matrix $H_1 = (I - 2 uu^{\\top})$ such that (we illustrate on a $4 \\times 3$ matrix)\n",
    "\n",
    "$$\n",
    "   H_1 A = \\begin{bmatrix}\n",
    "    * & * & * \\\\\n",
    "    0 & * & * \\\\\n",
    "    0 & * & * \\\\\n",
    "    0 & * & *\n",
    "   \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then, \n",
    "$$\n",
    "   H_2 H_1 A = \\begin{bmatrix}\n",
    "    * & * & * \\\\\n",
    "    0 & * & * \\\\\n",
    "    0 & 0 & * \\\\\n",
    "    0 & 0 & *\n",
    "   \\end{bmatrix},\n",
    "$$\n",
    "where\n",
    "$$\n",
    "  H_2 = \\begin{bmatrix}\n",
    "  1 & 0 \\\\\n",
    "  0 & H'_2, \n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "and $H'_2$ is a $3 \\times 3$ Householder matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, \n",
    "$$\n",
    "   H_3 H_2 H_1 A = \\begin{bmatrix}\n",
    "    * & * & * \\\\\n",
    "    0 & * & * \\\\\n",
    "    0 & 0 & * \\\\\n",
    "    0 & 0 & 0\n",
    "   \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "You can try to implement it yourself, it is simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## QR-decomposition: real life\n",
    "\n",
    "In reality, since this is a dense matrix factorization, you should implement the algorithm in terms of blocks.  \n",
    "\n",
    "Instead of using Householder transformation, we use **block Householder** transformation of the form\n",
    "\n",
    "$$H = (I - 2UU^*), $$\n",
    "\n",
    "where $U^* U = I$.\n",
    "\n",
    "This allows us to use BLAS-3 operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rank-revealing QR-decomposition\n",
    "\n",
    "The QR-decomposition can be also used to compute the (numerical) rank of the matrix, see \n",
    "\n",
    "[Rank-Revealing QR Factorizations and the Singular Value Decomposition, Y. P. Hong; C.-T. Pan](http://scgroup.hpclab.ceid.upatras.gr/class/SCII/Various/HongPan.pdf)\n",
    "\n",
    "It is done via so-called **rank-revealing** factorization.  \n",
    "\n",
    "It is based on the representation\n",
    "\n",
    "$$P A = Q R, $$\n",
    "\n",
    "where $P$ is the permutation matrix (it permutes columns), and  $R$ has the block form\n",
    "\n",
    "\n",
    "$$R = \\begin{bmatrix} R_{11} & R_{12} \\\\ 0 & R_{22}\\end{bmatrix}.$$\n",
    "\n",
    "The goal is to find $P$ such that the norm of $R_{22}$ is **small**, so you can find the numerical rank by looking at it.\n",
    "\n",
    "An estimate is $\\sigma_{r+1} \\leq \\Vert R_{22} \\Vert_2$ (check why)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "LU and QR decompositions can be computed using **direct methods** in finite amount of operations.\n",
    "\n",
    "What about Schur form and SVD?  \n",
    "\n",
    "They can not be computed by **direct methods** (why?) they can only be computed by **iterative methods**.\n",
    "\n",
    "Although iterative methods still have the same $\\mathcal{O}(n^3)$ complexity in floating point arithmetic\n",
    "thanks to fast convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Schur form\n",
    "\n",
    "Recall that every matrix can be written in the **Schur form**\n",
    "\n",
    "$$A = Q T Q^*,$$\n",
    "\n",
    "with triangular $T$ and unitary $Q$\n",
    "and this decomposition gives eigenvalues of the matrix (they are on the diagonal of $T$).\n",
    "\n",
    "The first and the main algorithm for computing the Schur form is the **QR**-algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## QR-algorithm\n",
    "The QR algorithm (Kublanovskaya and Francis independently proposed it in 1961).   \n",
    "\n",
    "\n",
    "\n",
    "<font color='red'> Do not **mix** QR algorithm and QR decomposition! </font>\n",
    "\n",
    "QR-decomposition is the representation of a matrix, whereas QR algorithm uses QR decomposition to compute the eigenvalues!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Way to QR-algorithm\n",
    "\n",
    "Consider the equation\n",
    "\n",
    "$$A = Q T Q^*,$$\n",
    "\n",
    "and rewrite it in the form\n",
    "\n",
    "$$\n",
    "   Q T = A Q.\n",
    "$$\n",
    "\n",
    "On the left we can see QR-factorization of the matrix $AQ$.\n",
    "\n",
    "We can use this to derive fixed-point iteration for the Schur form, also known as **QR-algorithm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Derivation of the QR-algorithm as fixed-point iteration\n",
    "Then we can write down the iterative process \n",
    "\n",
    "$$\n",
    "    Q_{k+1} R_{k+1} = A Q_k, \\quad Q_{k+1}^* A = R_{k+1} Q^*_k\n",
    "$$\n",
    "\n",
    "Introduce\n",
    "\n",
    "$$A_k = Q^* _k A Q_k = Q^*_k Q_{k+1} R_{k+1} = \\widehat{Q}_k R_{k+1}$$\n",
    "\n",
    "and the new approximation reads\n",
    "\n",
    "$$A_{k+1} = Q^*_{k+1} A Q_{k+1} = ( Q_{k+1}^* A = R_{k+1} Q^*_k)  = R_{k+1} \\widehat{Q}_k.$$\n",
    "\n",
    "So we arrive at the standard form of the QR algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The final formulas are then written in the classical **QRRQ**-form:\n",
    "\n",
    "1. Start from $A_0 = A$.\n",
    "2. Compute QR factorization of $A_k = Q_k R_k$.\n",
    "3. Set $A_{k+1} = R_k Q_k$.\n",
    "\n",
    "Iterate until $A_k$ is **triangular enough** (e.g. norm of subdiagonal part is small enough).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about the convergence and complexity\n",
    "\n",
    "**Statement**\n",
    "\n",
    "Matrices $A_k$ are unitary similar to $A$\n",
    "\n",
    "$A_k = Q^*_{k-1} A_{k-1} Q_{k-1} = (Q_{k-1} \\ldots Q_1)^* A (Q_{k-1} \\ldots Q_1)$\n",
    "\n",
    "and the product of unitary matrices is a unitary matrix.\n",
    "\n",
    "Complexity of each step is $\\mathcal{O}(n^3)$, if a general QR-decomposition is done.\n",
    "\n",
    "Our hope is that $A_k$ will be **very close to the triangular  matrix** for suffiently large $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leading 3x3 block of a:\n",
      "[[  2.41052440e+000   3.22429032e-017  -5.75075656e-017]\n",
      " [  1.55227759e-084   3.49984625e-001   5.16395464e-017]\n",
      " [  1.66750853e-220   4.85294271e-137   1.53236733e-002]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = 4\n",
    "a = [[1.0/(i + j + 0.5) for i in range(n)] for j in range(n)]\n",
    "niters = 100\n",
    "for k in range(niters):\n",
    "    q, rmat = np.linalg.qr(a)\n",
    "    a = rmat.dot(q)\n",
    "print 'Leading 3x3 block of a:'\n",
    "print a[:3, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergence and complexity of the QR-algorithm\n",
    "The convergence of the QR-algorithm is from the **largest eigenvalues** to the smallest.\n",
    "\n",
    "At least 2-3 iterations is needed for an eigenvalue. \n",
    "\n",
    "Each step is one QR-factorization and one matrix-by-matrix product. $\\mathcal{O}(n^3)$ complexity.\n",
    "\n",
    "It means, $\\mathcal{O}(n^4)$ complexity? \n",
    "\n",
    "Fortunately, not. \n",
    "\n",
    "We can also speedup the QR-algorithm by using **shifts**, since $A_k - \\lambda I$ has the same Schur vectors.\n",
    "\n",
    "We will discuss these details tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A few words about the SVD\n",
    "\n",
    "Last but not least: the **singular value decomposition** of matrices.\n",
    "\n",
    "$$A = U \\Sigma V^*.$$\n",
    "\n",
    "We can compute it via eigendecomposition of \n",
    "\n",
    "$$A^* A = U^* \\Sigma^2 U,$$\n",
    "\n",
    "but it is a **bad idea** (c.f. Gram matrices)\n",
    "\n",
    "We will discuss methods for computing SVD tomorrow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary of today's lecture\n",
    "\n",
    "- QR decomposition and Gram-Schmidt algorithm, reduction to a simpler form by Householder transformations\n",
    "- Schur decomposition and QR-algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next lecture\n",
    "- Efficient implementation of QR algorithm, convergence properties\n",
    "- Efficient computation of the SVD: 4 algorithms\n",
    "- It is done by reduction to simpler forms (tridiagonal, bidiagonal).\n",
    "- Applications of the SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        /*width:80%;*/\n",
       "        /*margin-left:auto !important;\n",
       "        margin-right:auto;*/\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\n",
       "    h2 {\n",
       "        font-family: 'Fenix', serif;\n",
       "    }\n",
       "    h3{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "\th4{\n",
       "\t\tfont-family: 'Fenix', serif;\n",
       "       }\n",
       "    h5 {\n",
       "        font-family: 'Alegreya Sans', sans-serif;\n",
       "    }\t   \n",
       "    div.text_cell_render{\n",
       "        font-family: 'Alegreya Sans',Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 1.2;\n",
       "        font-size: 120%;\n",
       "        /*width:70%;*/\n",
       "        /*margin-left:auto;*/\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\";\n",
       "\t\t\tfont-size: 90%;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 50pt;\n",
       "\t\tline-height: 110%;\n",
       "        color:#CD2305;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\t\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #CD2305;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    li {\n",
       "        line-height: 110%;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
